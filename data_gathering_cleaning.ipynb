{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for this project is gathered from the U.S. Energy Information Administration (EIA) [website](https://www.eia.gov)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import helper_functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to do a little manipulation to the text file from EIA. It is a text file with a bunch of line-separated JSON objects, but I massage it here to a proper JSON and export it as a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastline = None\n",
    "\n",
    "# Open and read text file\n",
    "with open(\"SEDS.txt\",\"r\") as f:\n",
    "    lineList = f.readlines()\n",
    "    \n",
    "    # Keep track of last line\n",
    "    lastline=lineList[-1]\n",
    "\n",
    "# Open text file and create new json to be written\n",
    "with open(\"SEDS.txt\",\"r\") as f, open(\"cleanfile.json\",\"w\") as g:\n",
    "    \n",
    "    # Iterate through each line of the text file\n",
    "    for i,line in enumerate(f,0):\n",
    "        \n",
    "        # First line gets [ and , to initialize the json\n",
    "        if i == 0:\n",
    "            line = \"[\"+str(line)+\",\"\n",
    "            g.write(line)\n",
    "            \n",
    "        # Last line gets ] to signal the end of the json\n",
    "        elif line == lastline:            \n",
    "            g.write(line)\n",
    "            g.write(\"]\")\n",
    "            \n",
    "        # Other lines get comma separation\n",
    "        else:\n",
    "            line = str(line)+\",\"\n",
    "            g.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('cleanfile.json', 'r')\n",
    "json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEDS.TNRSB.AL.A'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = json_data[3]\n",
    "string['series_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEDS.TNRSB.AL.A']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('SEDS\\.TNRSB\\..*',string['series_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following energy types were selected based on the categories in the [EIA educational page](https://www.eia.gov/energyexplained/energy-and-the-environment/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_types = [\n",
    "    'All Petroleum Products excluding Fuel Ethanol',\n",
    "    'Coal','Natural Gas including Supplemental Gaseous Fuels',\n",
    "    'Nuclear Power',\n",
    "    'Biomass',\n",
    "    'Fuel Ethanol excluding Denaturant',\n",
    "    'Geothermal',\n",
    "    'Hydroelectricity',\n",
    "    'Solar Energy',\n",
    "    'Wind Energy',\n",
    "    'Renewable Energy']\n",
    "\n",
    "# Make all lowercase in case some pages have inconsistent letter casing\n",
    "for i in range(len(energy_types)):\n",
    "    energy_types[i] = energy_types[i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scrape to get the information for each of the above types of energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'user-agent': 'Safari/13.0.2 (Macintosh; Intel Mac OS X 10_15)'}\n",
    "base_url = 'https://www.eia.gov/opendata/qb.php'\n",
    "consumption_suffix = '?category=40204'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_page = helper_functions.get_page(base_url+consumption_suffix,headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dict to store all info across every sector and energy type by state\n",
    "env_series_ids = {}\n",
    "\n",
    "# Start by scraping the consumption website in order to get the list of available sectors  \n",
    "consumption_sectors = consumption_page.find('div',{'class':'pagecontent mr_temp2'})\n",
    "\n",
    "# Store sector url suffixes in a list\n",
    "sector_url_suffixes = [sector.a['href'] for sector in consumption_sectors.find_all('li')[:7]]\n",
    "\n",
    "# Loop 1 - iterate through each sector\n",
    "for sector_url_suffix in sector_url_suffixes:\n",
    "    \n",
    "    # Scrape the sector page\n",
    "    sector_page = helper_functions.get_page(base_url+sector_url_suffix,headers)    \n",
    "\n",
    "    # Go into first url and grab tags of all children categories\n",
    "    children_categories = sector_page.find('section').ul.find_all('li')\n",
    "\n",
    "    # Store the urls of children cats (ccats = children categories)\n",
    "    ccats_url_suffixes = [children_category.a['href'] \n",
    "                          for children_category in children_categories\n",
    "                          if children_category.text.lower() in energy_types]\n",
    "    \n",
    "    # Loop 2 - for each sector, iterate through the relevant types of energy consumption to get state-level data\n",
    "    for ccats_url_suffix in ccats_url_suffixes:\n",
    "        \n",
    "        # Scrape the child category page\n",
    "        child_category_page = helper_functions.get_page(base_url+ccats_url_suffix,headers)\n",
    "\n",
    "        # Grab tags of all energy unit children categories. Only want Btu\n",
    "        energy_unit_cats = child_category_page.find('div',{'class':'main_col'}).ul.find_all('li')\n",
    "\n",
    "        # Store only the url of the 'Btu' children category. I make a list and select only the first element \n",
    "        # because sometimes there will be two energy unit options or just one. This way ensures we only take \n",
    "        # the Btu option.\n",
    "        btu_url_suffix = [energy_unit.a['href'] \n",
    "                   for energy_unit in energy_unit_cats\n",
    "                   if energy_unit.text == 'Btu'][0]\n",
    "        \n",
    "        # Scrape the Btu page\n",
    "        btu_page = helper_functions.get_page(base_url+btu_url_suffix,headers)\n",
    "        \n",
    "        # Get list of states by their tags\n",
    "        states = btu_page.find('div',{'class':'main_col'}).ul.find_all('li')\n",
    "        \n",
    "        # Get url suffixes for each state\n",
    "        state_url_suffixes = [state.a['href'] for state in states]\n",
    "        \n",
    "        # Isolate the sector and energy type\n",
    "        sector = btu_page.find('div',{'class':'main_col'}).h3.find_all('a')[3].text\n",
    "        energy_type = btu_page.find('div',{'class':'main_col'}).h3.find_all('a')[4].text\n",
    "        \n",
    "        # Add these to a dict which will be the values of the overarching env_series_ids dict\n",
    "        series_id_values = {'sector':sector,'energy_type':energy_type}\n",
    "        \n",
    "        # Parse through url suffixes to get and store the series ids we want to use to parse the big JSON\n",
    "        for state_suffix in state_url_suffixes:\n",
    "            series_id = re.findall('SEDS.*',state_suffix)[0]\n",
    "            env_series_ids[series_id] = series_id_values\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse energy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up empty bucket for parsed data\n",
    "environmental_data = []\n",
    "\n",
    "# Iterate through big json to parse relevant info\n",
    "for single_json in json_data:\n",
    "    \n",
    "    # Only parse entries that have the series ids that we care about\n",
    "    if single_json.get('series_id') in env_series_ids.keys():\n",
    "        single_data_entry = {}\n",
    "        single_data_entry['series_id'] = single_json['series_id']\n",
    "        single_data_entry['sector'] = env_series_ids[single_json['series_id']]['sector']\n",
    "        single_data_entry['energy_type'] = env_series_ids[single_json['series_id']]['energy_type']\n",
    "        single_data_entry['data'] = single_json['data']\n",
    "        single_data_entry['state'] = re.findall(', .*$',single_json['name'])[0][2:]\n",
    "        single_data_entry['units'] = single_json['units']\n",
    "        environmental_data.append(single_data_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scrape for population and GDP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_url_suffix = '?category=40367'\n",
    "gdp_url_suffix = '?category=40828'\n",
    "pop_gdp_url_suffixes = [population_url_suffix, gdp_url_suffix]\n",
    "\n",
    "# Create container for  data\n",
    "pop_gdp_series_ids = {}\n",
    "\n",
    "for pop_gdp_url_suffix in pop_gdp_url_suffixes:\n",
    "    \n",
    "    # Scrape population page\n",
    "    page = helper_functions.get_page(base_url + pop_gdp_url_suffix,headers)\n",
    "\n",
    "    # Isolate html tags containing urls for each state\n",
    "    state_tags = page.find('div',{'class':'main_col'}).ul.find_all('li')\n",
    "\n",
    "    # Extract and save each state url suffix\n",
    "    state_url_suffixes = [state_tag.a['href'] \n",
    "                          for state_tag in state_tags]\n",
    "\n",
    "    # Iterate through each state url suffix to extract features\n",
    "    for state_url_suffix in state_url_suffixes:\n",
    "\n",
    "        # Scrape each state's series page\n",
    "        state_page = helper_functions.get_page(base_url + state_url_suffix,headers)\n",
    "\n",
    "        # Isolate html tags containing state name, get text from tag, parse for name\n",
    "        api_call_tags = state_page.find('div',{'class':'main_col'}).find('div',{'class':'api_call_container'})\n",
    "        state_text = api_call_tags.find_all('p')[1].text\n",
    "        state = re.findall('(, )(.*)',state_text)[0][1]\n",
    "        \n",
    "        # Isolate html tags containing description (gdp or pop), get text from tag\n",
    "        main_col_tags = state_page.find('div',{'class':'main_col'}).h3\n",
    "        desc = main_col_tags.find_all('a')[2].text\n",
    "        \n",
    "        # Parse url suffix for series id\n",
    "        series_id = re.findall('SEDS.*',state_url_suffix)[0]\n",
    "\n",
    "        # Add to data container\n",
    "        values = {'state':state,'description':desc}\n",
    "        pop_gdp_series_ids[series_id] = values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse population and gdp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up empty bucket for parsed data\n",
    "pop_gdp_data = []\n",
    "\n",
    "# Iterate through big json to parse relevant info\n",
    "for single_json in json_data:\n",
    "    \n",
    "    # Only parse entries that have the series ids that we care about\n",
    "    if single_json.get('series_id') in pop_gdp_series_ids.keys():\n",
    "        single_data_entry = {}\n",
    "        single_data_entry['series_id'] = single_json['series_id']\n",
    "        single_data_entry['description'] = pop_gdp_series_ids[single_json['series_id']]['description']\n",
    "        single_data_entry['units'] = single_json['units']\n",
    "        single_data_entry['data'] = single_json['data']\n",
    "        single_data_entry['state'] = pop_gdp_series_ids[single_json['series_id']]['state']\n",
    "        pop_gdp_data.append(single_data_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asserts': {'msg': 0, 'regular': 0, 'rollovers': 0, 'user': 10, 'warning': 0},\n",
      " 'connections': {'active': 1,\n",
      "                 'available': 3272,\n",
      "                 'current': 4,\n",
      "                 'totalCreated': 4},\n",
      " 'electionMetrics': {'averageCatchUpOps': 0.0,\n",
      "                     'catchUpTakeover': {'called': 0, 'successful': 0},\n",
      "                     'electionTimeout': {'called': 0, 'successful': 0},\n",
      "                     'freezeTimeout': {'called': 0, 'successful': 0},\n",
      "                     'numCatchUps': 0,\n",
      "                     'numCatchUpsAlreadyCaughtUp': 0,\n",
      "                     'numCatchUpsFailedWithError': 0,\n",
      "                     'numCatchUpsFailedWithNewTerm': 0,\n",
      "                     'numCatchUpsFailedWithReplSetAbortPrimaryCatchUpCmd': 0,\n",
      "                     'numCatchUpsSkipped': 0,\n",
      "                     'numCatchUpsSucceeded': 0,\n",
      "                     'numCatchUpsTimedOut': 0,\n",
      "                     'numStepDownsCausedByHigherTerm': 0,\n",
      "                     'priorityTakeover': {'called': 0, 'successful': 0},\n",
      "                     'stepUpCmd': {'called': 0, 'successful': 0}},\n",
      " 'extra_info': {'note': 'fields vary by platform', 'page_faults': 3},\n",
      " 'flowControl': {'enabled': True,\n",
      "                 'isLagged': False,\n",
      "                 'isLaggedCount': 0,\n",
      "                 'isLaggedTimeMicros': 0,\n",
      "                 'locksPerOp': 0.0,\n",
      "                 'sustainerRate': 0,\n",
      "                 'targetRateLimit': 1000000000,\n",
      "                 'timeAcquiringMicros': 3},\n",
      " 'freeMonitoring': {'lastRunTime': '2020-01-09T15:38:04.184-0500',\n",
      "                    'metricsErrors': 0,\n",
      "                    'registerErrors': 0,\n",
      "                    'retryIntervalSecs': 10,\n",
      "                    'state': 'enabled'},\n",
      " 'globalLock': {'activeClients': {'readers': 0, 'total': 0, 'writers': 0},\n",
      "                'currentQueue': {'readers': 0, 'total': 0, 'writers': 0},\n",
      "                'totalTime': 125472000},\n",
      " 'host': 'Marcos-MacBook-Pro.local',\n",
      " 'localTime': datetime.datetime(2020, 1, 9, 20, 38, 8, 302000),\n",
      " 'locks': {'Collection': {'acquireCount': {'R': 1, 'W': 2, 'r': 176, 'w': 10}},\n",
      "           'Database': {'acquireCount': {'W': 12, 'r': 167, 'w': 4}},\n",
      "           'Global': {'acquireCount': {'W': 4, 'r': 415, 'w': 15}},\n",
      "           'Mutex': {'acquireCount': {'r': 183}},\n",
      "           'ParallelBatchWriterMode': {'acquireCount': {'r': 25}},\n",
      "           'ReplicationStateTransition': {'acquireCount': {'w': 434}},\n",
      "           'oplog': {'acquireCount': {'r': 126}}},\n",
      " 'logicalSessionRecordCache': {'activeSessionsCount': 2,\n",
      "                               'lastSessionsCollectionJobCursorsClosed': 0,\n",
      "                               'lastSessionsCollectionJobDurationMillis': 50,\n",
      "                               'lastSessionsCollectionJobEntriesEnded': 0,\n",
      "                               'lastSessionsCollectionJobEntriesRefreshed': 0,\n",
      "                               'lastSessionsCollectionJobTimestamp': datetime.datetime(2020, 1, 9, 20, 36, 3, 718000),\n",
      "                               'lastTransactionReaperJobDurationMillis': 0,\n",
      "                               'lastTransactionReaperJobEntriesCleanedUp': 0,\n",
      "                               'lastTransactionReaperJobTimestamp': datetime.datetime(2020, 1, 9, 20, 36, 3, 718000),\n",
      "                               'sessionCatalogSize': 0,\n",
      "                               'sessionsCollectionJobCount': 1,\n",
      "                               'transactionReaperJobCount': 1},\n",
      " 'mem': {'bits': 64, 'resident': 39, 'supported': True, 'virtual': 5398},\n",
      " 'metrics': {'commands': {'<UNKNOWN>': 0,\n",
      "                          '_addShard': {'failed': 0, 'total': 0},\n",
      "                          '_cloneCatalogData': {'failed': 0, 'total': 0},\n",
      "                          '_cloneCollectionOptionsFromPrimaryShard': {'failed': 0,\n",
      "                                                                      'total': 0},\n",
      "                          '_configsvrAddShard': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrAddShardToZone': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrBalancerStart': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrBalancerStatus': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrBalancerStop': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrCommitChunkMerge': {'failed': 0,\n",
      "                                                         'total': 0},\n",
      "                          '_configsvrCommitChunkMigration': {'failed': 0,\n",
      "                                                             'total': 0},\n",
      "                          '_configsvrCommitChunkSplit': {'failed': 0,\n",
      "                                                         'total': 0},\n",
      "                          '_configsvrCommitMovePrimary': {'failed': 0,\n",
      "                                                          'total': 0},\n",
      "                          '_configsvrCreateCollection': {'failed': 0,\n",
      "                                                         'total': 0},\n",
      "                          '_configsvrCreateDatabase': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrDropCollection': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrDropDatabase': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrEnableSharding': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrMoveChunk': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrMovePrimary': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrRemoveShard': {'failed': 0, 'total': 0},\n",
      "                          '_configsvrRemoveShardFromZone': {'failed': 0,\n",
      "                                                            'total': 0},\n",
      "                          '_configsvrShardCollection': {'failed': 0,\n",
      "                                                        'total': 0},\n",
      "                          '_configsvrUpdateZoneKeyRange': {'failed': 0,\n",
      "                                                           'total': 0},\n",
      "                          '_flushDatabaseCacheUpdates': {'failed': 0,\n",
      "                                                         'total': 0},\n",
      "                          '_flushRoutingTableCacheUpdates': {'failed': 0,\n",
      "                                                             'total': 0},\n",
      "                          '_getNextSessionMods': {'failed': 0, 'total': 0},\n",
      "                          '_getUserCacheGeneration': {'failed': 0, 'total': 0},\n",
      "                          '_isSelf': {'failed': 0, 'total': 0},\n",
      "                          '_mergeAuthzCollections': {'failed': 0, 'total': 0},\n",
      "                          '_migrateClone': {'failed': 0, 'total': 0},\n",
      "                          '_movePrimary': {'failed': 0, 'total': 0},\n",
      "                          '_recvChunkAbort': {'failed': 0, 'total': 0},\n",
      "                          '_recvChunkCommit': {'failed': 0, 'total': 0},\n",
      "                          '_recvChunkStart': {'failed': 0, 'total': 0},\n",
      "                          '_recvChunkStatus': {'failed': 0, 'total': 0},\n",
      "                          '_shardsvrShardCollection': {'failed': 0, 'total': 0},\n",
      "                          '_transferMods': {'failed': 0, 'total': 0},\n",
      "                          'abortTransaction': {'failed': 0, 'total': 0},\n",
      "                          'aggregate': {'failed': 0, 'total': 0},\n",
      "                          'appendOplogNote': {'failed': 0, 'total': 0},\n",
      "                          'applyOps': {'failed': 0, 'total': 0},\n",
      "                          'authenticate': {'failed': 0, 'total': 0},\n",
      "                          'availableQueryOptions': {'failed': 0, 'total': 0},\n",
      "                          'buildInfo': {'failed': 0, 'total': 2},\n",
      "                          'checkShardingIndex': {'failed': 0, 'total': 0},\n",
      "                          'cleanupOrphaned': {'failed': 0, 'total': 0},\n",
      "                          'cloneCollection': {'failed': 0, 'total': 0},\n",
      "                          'cloneCollectionAsCapped': {'failed': 0, 'total': 0},\n",
      "                          'collMod': {'failed': 0, 'total': 0},\n",
      "                          'collStats': {'failed': 0, 'total': 0},\n",
      "                          'commitTransaction': {'failed': 0, 'total': 0},\n",
      "                          'compact': {'failed': 0, 'total': 0},\n",
      "                          'connPoolStats': {'failed': 0, 'total': 0},\n",
      "                          'connPoolSync': {'failed': 0, 'total': 0},\n",
      "                          'connectionStatus': {'failed': 0, 'total': 0},\n",
      "                          'convertToCapped': {'failed': 0, 'total': 0},\n",
      "                          'coordinateCommitTransaction': {'failed': 0,\n",
      "                                                          'total': 0},\n",
      "                          'count': {'failed': 0, 'total': 0},\n",
      "                          'create': {'failed': 0, 'total': 0},\n",
      "                          'createIndexes': {'failed': 0, 'total': 1},\n",
      "                          'createRole': {'failed': 0, 'total': 0},\n",
      "                          'createUser': {'failed': 0, 'total': 0},\n",
      "                          'currentOp': {'failed': 0, 'total': 0},\n",
      "                          'dataSize': {'failed': 0, 'total': 0},\n",
      "                          'dbHash': {'failed': 0, 'total': 0},\n",
      "                          'dbStats': {'failed': 0, 'total': 0},\n",
      "                          'delete': {'failed': 0, 'total': 0},\n",
      "                          'distinct': {'failed': 0, 'total': 0},\n",
      "                          'driverOIDTest': {'failed': 0, 'total': 0},\n",
      "                          'drop': {'failed': 0, 'total': 0},\n",
      "                          'dropAllRolesFromDatabase': {'failed': 0, 'total': 0},\n",
      "                          'dropAllUsersFromDatabase': {'failed': 0, 'total': 0},\n",
      "                          'dropConnections': {'failed': 0, 'total': 0},\n",
      "                          'dropDatabase': {'failed': 0, 'total': 0},\n",
      "                          'dropIndexes': {'failed': 0, 'total': 0},\n",
      "                          'dropRole': {'failed': 0, 'total': 0},\n",
      "                          'dropUser': {'failed': 0, 'total': 0},\n",
      "                          'endSessions': {'failed': 0, 'total': 0},\n",
      "                          'explain': {'failed': 0, 'total': 0},\n",
      "                          'features': {'failed': 0, 'total': 0},\n",
      "                          'filemd5': {'failed': 0, 'total': 0},\n",
      "                          'find': {'failed': 0, 'total': 1},\n",
      "                          'findAndModify': {'failed': 0, 'total': 0},\n",
      "                          'flushRouterConfig': {'failed': 0, 'total': 0},\n",
      "                          'fsync': {'failed': 0, 'total': 0},\n",
      "                          'fsyncUnlock': {'failed': 0, 'total': 0},\n",
      "                          'geoSearch': {'failed': 0, 'total': 0},\n",
      "                          'getCmdLineOpts': {'failed': 0, 'total': 0},\n",
      "                          'getDatabaseVersion': {'failed': 0, 'total': 0},\n",
      "                          'getDiagnosticData': {'failed': 0, 'total': 0},\n",
      "                          'getFreeMonitoringStatus': {'failed': 0, 'total': 2},\n",
      "                          'getLastError': {'failed': 0, 'total': 0},\n",
      "                          'getLog': {'failed': 0, 'total': 1},\n",
      "                          'getMore': {'failed': 0, 'total': 0},\n",
      "                          'getParameter': {'failed': 0, 'total': 0},\n",
      "                          'getShardMap': {'failed': 0, 'total': 0},\n",
      "                          'getShardVersion': {'failed': 0, 'total': 0},\n",
      "                          'getnonce': {'failed': 0, 'total': 0},\n",
      "                          'grantPrivilegesToRole': {'failed': 0, 'total': 0},\n",
      "                          'grantRolesToRole': {'failed': 0, 'total': 0},\n",
      "                          'grantRolesToUser': {'failed': 0, 'total': 0},\n",
      "                          'hostInfo': {'failed': 0, 'total': 0},\n",
      "                          'insert': {'failed': 0, 'total': 0},\n",
      "                          'invalidateUserCache': {'failed': 0, 'total': 0},\n",
      "                          'isMaster': {'failed': 0, 'total': 26},\n",
      "                          'killAllSessions': {'failed': 0, 'total': 0},\n",
      "                          'killAllSessionsByPattern': {'failed': 0, 'total': 0},\n",
      "                          'killCursors': {'failed': 0, 'total': 0},\n",
      "                          'killOp': {'failed': 0, 'total': 0},\n",
      "                          'killSessions': {'failed': 0, 'total': 0},\n",
      "                          'listCollections': {'failed': 0, 'total': 0},\n",
      "                          'listCommands': {'failed': 0, 'total': 0},\n",
      "                          'listDatabases': {'failed': 0, 'total': 0},\n",
      "                          'listIndexes': {'failed': 2, 'total': 2},\n",
      "                          'lockInfo': {'failed': 0, 'total': 0},\n",
      "                          'logRotate': {'failed': 0, 'total': 0},\n",
      "                          'logout': {'failed': 0, 'total': 0},\n",
      "                          'mapReduce': {'failed': 0, 'total': 0},\n",
      "                          'mapreduce': {'shardedfinish': {'failed': 0,\n",
      "                                                          'total': 0}},\n",
      "                          'mergeChunks': {'failed': 0, 'total': 0},\n",
      "                          'moveChunk': {'failed': 0, 'total': 0},\n",
      "                          'ping': {'failed': 0, 'total': 0},\n",
      "                          'planCacheClear': {'failed': 0, 'total': 0},\n",
      "                          'planCacheClearFilters': {'failed': 0, 'total': 0},\n",
      "                          'planCacheListFilters': {'failed': 0, 'total': 0},\n",
      "                          'planCacheListPlans': {'failed': 0, 'total': 0},\n",
      "                          'planCacheListQueryShapes': {'failed': 0, 'total': 0},\n",
      "                          'planCacheSetFilter': {'failed': 0, 'total': 0},\n",
      "                          'prepareTransaction': {'failed': 0, 'total': 0},\n",
      "                          'profile': {'failed': 0, 'total': 0},\n",
      "                          'reIndex': {'failed': 0, 'total': 0},\n",
      "                          'refreshSessions': {'failed': 0, 'total': 0},\n",
      "                          'renameCollection': {'failed': 0, 'total': 0},\n",
      "                          'repairCursor': {'failed': 0, 'total': 0},\n",
      "                          'repairDatabase': {'failed': 0, 'total': 0},\n",
      "                          'replSetAbortPrimaryCatchUp': {'failed': 0,\n",
      "                                                         'total': 0},\n",
      "                          'replSetFreeze': {'failed': 0, 'total': 0},\n",
      "                          'replSetGetConfig': {'failed': 0, 'total': 0},\n",
      "                          'replSetGetRBID': {'failed': 0, 'total': 0},\n",
      "                          'replSetGetStatus': {'failed': 1, 'total': 1},\n",
      "                          'replSetHeartbeat': {'failed': 0, 'total': 0},\n",
      "                          'replSetInitiate': {'failed': 0, 'total': 0},\n",
      "                          'replSetMaintenance': {'failed': 0, 'total': 0},\n",
      "                          'replSetReconfig': {'failed': 0, 'total': 0},\n",
      "                          'replSetRequestVotes': {'failed': 0, 'total': 0},\n",
      "                          'replSetResizeOplog': {'failed': 0, 'total': 0},\n",
      "                          'replSetStepDown': {'failed': 0, 'total': 0},\n",
      "                          'replSetStepDownWithForce': {'failed': 0, 'total': 0},\n",
      "                          'replSetStepUp': {'failed': 0, 'total': 0},\n",
      "                          'replSetSyncFrom': {'failed': 0, 'total': 0},\n",
      "                          'replSetUpdatePosition': {'failed': 0, 'total': 0},\n",
      "                          'resetError': {'failed': 0, 'total': 0},\n",
      "                          'revokePrivilegesFromRole': {'failed': 0, 'total': 0},\n",
      "                          'revokeRolesFromRole': {'failed': 0, 'total': 0},\n",
      "                          'revokeRolesFromUser': {'failed': 0, 'total': 0},\n",
      "                          'rolesInfo': {'failed': 0, 'total': 0},\n",
      "                          'saslContinue': {'failed': 0, 'total': 0},\n",
      "                          'saslStart': {'failed': 0, 'total': 0},\n",
      "                          'serverStatus': {'failed': 0, 'total': 1},\n",
      "                          'setFeatureCompatibilityVersion': {'failed': 0,\n",
      "                                                             'total': 0},\n",
      "                          'setFreeMonitoring': {'failed': 0, 'total': 1},\n",
      "                          'setIndexCommitQuorum': {'failed': 0, 'total': 0},\n",
      "                          'setParameter': {'failed': 0, 'total': 0},\n",
      "                          'setShardVersion': {'failed': 0, 'total': 0},\n",
      "                          'shardConnPoolStats': {'failed': 0, 'total': 0},\n",
      "                          'shardingState': {'failed': 0, 'total': 0},\n",
      "                          'shutdown': {'failed': 0, 'total': 0},\n",
      "                          'splitChunk': {'failed': 0, 'total': 0},\n",
      "                          'splitVector': {'failed': 0, 'total': 0},\n",
      "                          'startRecordingTraffic': {'failed': 0, 'total': 0},\n",
      "                          'startSession': {'failed': 0, 'total': 0},\n",
      "                          'stopRecordingTraffic': {'failed': 0, 'total': 0},\n",
      "                          'top': {'failed': 0, 'total': 0},\n",
      "                          'touch': {'failed': 0, 'total': 0},\n",
      "                          'unsetSharding': {'failed': 0, 'total': 0},\n",
      "                          'update': {'failed': 0, 'total': 0},\n",
      "                          'updateRole': {'failed': 0, 'total': 0},\n",
      "                          'updateUser': {'failed': 0, 'total': 0},\n",
      "                          'usersInfo': {'failed': 0, 'total': 0},\n",
      "                          'validate': {'failed': 0, 'total': 0},\n",
      "                          'voteCommitIndexBuild': {'failed': 0, 'total': 0},\n",
      "                          'waitForFailPoint': {'failed': 0, 'total': 0},\n",
      "                          'whatsmyuri': {'failed': 0, 'total': 1}},\n",
      "             'cursor': {'open': {'noTimeout': 0, 'pinned': 0, 'total': 0},\n",
      "                        'timedOut': 0},\n",
      "             'document': {'deleted': 0,\n",
      "                          'inserted': 0,\n",
      "                          'returned': 0,\n",
      "                          'updated': 0},\n",
      "             'getLastError': {'wtime': {'num': 0, 'totalMillis': 0},\n",
      "                              'wtimeouts': 0},\n",
      "             'operation': {'scanAndOrder': 0, 'writeConflicts': 0},\n",
      "             'query': {'planCacheTotalSizeEstimateBytes': 0,\n",
      "                       'updateOneOpStyleBroadcastWithExactIDCount': 0},\n",
      "             'queryExecutor': {'scanned': 0, 'scannedObjects': 0},\n",
      "             'record': {'moves': 0},\n",
      "             'repl': {'apply': {'attemptsToBecomeSecondary': 0,\n",
      "                                'batchSize': 0,\n",
      "                                'batches': {'num': 0, 'totalMillis': 0},\n",
      "                                'ops': 0},\n",
      "                      'buffer': {'count': 0, 'maxSizeBytes': 0, 'sizeBytes': 0},\n",
      "                      'executor': {'networkInterface': 'DEPRECATED: '\n",
      "                                                       'getDiagnosticString is '\n",
      "                                                       'deprecated in '\n",
      "                                                       'NetworkInterfaceTL',\n",
      "                                   'pool': {'inProgressCount': 0},\n",
      "                                   'queues': {'networkInProgress': 0,\n",
      "                                              'sleepers': 0},\n",
      "                                   'shuttingDown': False,\n",
      "                                   'unsignaledEvents': 0},\n",
      "                      'initialSync': {'completed': 0,\n",
      "                                      'failedAttempts': 0,\n",
      "                                      'failures': 0},\n",
      "                      'network': {'bytes': 0,\n",
      "                                  'getmores': {'num': 0, 'totalMillis': 0},\n",
      "                                  'notMasterLegacyUnacknowledgedWrites': 0,\n",
      "                                  'notMasterUnacknowledgedWrites': 0,\n",
      "                                  'ops': 0,\n",
      "                                  'readersCreated': 0},\n",
      "                      'stepDown': {'userOperationsKilled': 0,\n",
      "                                   'userOperationsRunning': 0}},\n",
      "             'ttl': {'deletedDocuments': 0, 'passes': 2}},\n",
      " 'network': {'bytesIn': 3829,\n",
      "             'bytesOut': 11792,\n",
      "             'compression': {'snappy': {'compressor': {'bytesIn': 0,\n",
      "                                                       'bytesOut': 0},\n",
      "                                        'decompressor': {'bytesIn': 0,\n",
      "                                                         'bytesOut': 0}},\n",
      "                             'zlib': {'compressor': {'bytesIn': 0,\n",
      "                                                     'bytesOut': 0},\n",
      "                                      'decompressor': {'bytesIn': 0,\n",
      "                                                       'bytesOut': 0}},\n",
      "                             'zstd': {'compressor': {'bytesIn': 0,\n",
      "                                                     'bytesOut': 0},\n",
      "                                      'decompressor': {'bytesIn': 0,\n",
      "                                                       'bytesOut': 0}}},\n",
      "             'numRequests': 35,\n",
      "             'physicalBytesIn': 3829,\n",
      "             'physicalBytesOut': 11792,\n",
      "             'serviceExecutorTaskStats': {'executor': 'passthrough',\n",
      "                                          'threadsRunning': 4}},\n",
      " 'ok': 1.0,\n",
      " 'opLatencies': {'commands': {'latency': 166266, 'ops': 34},\n",
      "                 'reads': {'latency': 0, 'ops': 0},\n",
      "                 'transactions': {'latency': 0, 'ops': 0},\n",
      "                 'writes': {'latency': 0, 'ops': 0}},\n",
      " 'opReadConcernCounters': {'available': 0,\n",
      "                           'linearizable': 0,\n",
      "                           'local': 0,\n",
      "                           'majority': 0,\n",
      "                           'none': 1,\n",
      "                           'snapshot': 0},\n",
      " 'opcounters': {'command': 38,\n",
      "                'delete': 0,\n",
      "                'getmore': 0,\n",
      "                'insert': 0,\n",
      "                'query': 1,\n",
      "                'update': 0},\n",
      " 'opcountersRepl': {'command': 0,\n",
      "                    'delete': 0,\n",
      "                    'getmore': 0,\n",
      "                    'insert': 0,\n",
      "                    'query': 0,\n",
      "                    'update': 0},\n",
      " 'pid': 48245,\n",
      " 'process': 'mongod',\n",
      " 'storageEngine': {'backupCursorOpen': False,\n",
      "                   'dropPendingIdents': 0,\n",
      "                   'name': 'wiredTiger',\n",
      "                   'oldestRequiredTimestampForCrashRecovery': Timestamp(0, 0),\n",
      "                   'persistent': True,\n",
      "                   'readOnly': False,\n",
      "                   'supportsCommittedReads': True,\n",
      "                   'supportsPendingDrops': True,\n",
      "                   'supportsSnapshotReadConcern': True},\n",
      " 'trafficRecording': {'running': False},\n",
      " 'transactions': {'currentActive': 0,\n",
      "                  'currentInactive': 0,\n",
      "                  'currentOpen': 0,\n",
      "                  'currentPrepared': 0,\n",
      "                  'retriedCommandsCount': 0,\n",
      "                  'retriedStatementsCount': 0,\n",
      "                  'totalAborted': 0,\n",
      "                  'totalCommitted': 0,\n",
      "                  'totalPrepared': 0,\n",
      "                  'totalPreparedThenAborted': 0,\n",
      "                  'totalPreparedThenCommitted': 0,\n",
      "                  'totalStarted': 0,\n",
      "                  'transactionsCollectionWriteCount': 0},\n",
      " 'transportSecurity': {'1.0': 0, '1.1': 0, '1.2': 0, '1.3': 0, 'unknown': 0},\n",
      " 'twoPhaseCommitCoordinator': {'currentInSteps': {'deletingCoordinatorDoc': 0,\n",
      "                                                  'waitingForDecisionAcks': 0,\n",
      "                                                  'waitingForVotes': 0,\n",
      "                                                  'writingDecision': 0,\n",
      "                                                  'writingParticipantList': 0},\n",
      "                               'totalAbortedTwoPhaseCommit': 0,\n",
      "                               'totalCommittedTwoPhaseCommit': 0,\n",
      "                               'totalCreated': 0,\n",
      "                               'totalStartedTwoPhaseCommit': 0},\n",
      " 'uptime': 126.0,\n",
      " 'uptimeEstimate': 125,\n",
      " 'uptimeMillis': 125477,\n",
      " 'version': '4.2.2',\n",
      " 'wiredTiger': {'async': {'current work queue length': 0,\n",
      "                          'maximum work queue length': 0,\n",
      "                          'number of allocation state races': 0,\n",
      "                          'number of flush calls': 0,\n",
      "                          'number of operation slots viewed for allocation': 0,\n",
      "                          'number of times operation allocation failed': 0,\n",
      "                          'number of times worker found no work': 0,\n",
      "                          'total allocations': 0,\n",
      "                          'total compact calls': 0,\n",
      "                          'total insert calls': 0,\n",
      "                          'total remove calls': 0,\n",
      "                          'total search calls': 0,\n",
      "                          'total update calls': 0},\n",
      "                'block-manager': {'blocks pre-loaded': 0,\n",
      "                                  'blocks read': 3,\n",
      "                                  'blocks written': 38,\n",
      "                                  'bytes read': 12288,\n",
      "                                  'bytes written': 180224,\n",
      "                                  'bytes written for checkpoint': 180224,\n",
      "                                  'mapped blocks read': 0,\n",
      "                                  'mapped bytes read': 0},\n",
      "                'cache': {'application threads page read from disk to cache count': 0,\n",
      "                          'application threads page read from disk to cache time (usecs)': 0,\n",
      "                          'application threads page write from cache to disk count': 18,\n",
      "                          'application threads page write from cache to disk time (usecs)': 3511,\n",
      "                          'bytes belonging to page images in the cache': 0,\n",
      "                          'bytes belonging to the cache overflow table in the cache': 182,\n",
      "                          'bytes currently in the cache': 47240,\n",
      "                          'bytes dirty in the cache cumulative': 12645,\n",
      "                          'bytes not belonging to page images in the cache': 47240,\n",
      "                          'bytes read into cache': 0,\n",
      "                          'bytes written from cache': 32584,\n",
      "                          'cache overflow cursor application thread wait time (usecs)': 0,\n",
      "                          'cache overflow cursor internal thread wait time (usecs)': 0,\n",
      "                          'cache overflow score': 0,\n",
      "                          'cache overflow table entries': 0,\n",
      "                          'cache overflow table insert calls': 0,\n",
      "                          'cache overflow table max on-disk size': 0,\n",
      "                          'cache overflow table on-disk size': 0,\n",
      "                          'cache overflow table remove calls': 0,\n",
      "                          'checkpoint blocked page eviction': 0,\n",
      "                          'eviction calls to get a page': 10,\n",
      "                          'eviction calls to get a page found queue empty': 10,\n",
      "                          'eviction calls to get a page found queue empty after locking': 0,\n",
      "                          'eviction currently operating in aggressive mode': 0,\n",
      "                          'eviction empty score': 0,\n",
      "                          'eviction passes of a file': 0,\n",
      "                          'eviction server candidate queue empty when topping up': 0,\n",
      "                          'eviction server candidate queue not empty when topping up': 0,\n",
      "                          'eviction server evicting pages': 0,\n",
      "                          'eviction server slept, because we did not make progress with eviction': 0,\n",
      "                          'eviction server unable to reach eviction goal': 0,\n",
      "                          'eviction server waiting for a leaf page': 2,\n",
      "                          'eviction state': 128,\n",
      "                          'eviction walk target pages histogram - 0-9': 0,\n",
      "                          'eviction walk target pages histogram - 10-31': 0,\n",
      "                          'eviction walk target pages histogram - 128 and higher': 0,\n",
      "                          'eviction walk target pages histogram - 32-63': 0,\n",
      "                          'eviction walk target pages histogram - 64-128': 0,\n",
      "                          'eviction walk target strategy both clean and dirty pages': 0,\n",
      "                          'eviction walk target strategy only clean pages': 0,\n",
      "                          'eviction walk target strategy only dirty pages': 0,\n",
      "                          'eviction walks abandoned': 0,\n",
      "                          'eviction walks gave up because they restarted their walk twice': 0,\n",
      "                          'eviction walks gave up because they saw too many pages and found no candidates': 0,\n",
      "                          'eviction walks gave up because they saw too many pages and found too few candidates': 0,\n",
      "                          'eviction walks reached end of tree': 0,\n",
      "                          'eviction walks started from root of tree': 0,\n",
      "                          'eviction walks started from saved location in tree': 0,\n",
      "                          'eviction worker thread active': 4,\n",
      "                          'eviction worker thread created': 0,\n",
      "                          'eviction worker thread evicting pages': 0,\n",
      "                          'eviction worker thread removed': 0,\n",
      "                          'eviction worker thread stable number': 0,\n",
      "                          'files with active eviction walks': 0,\n",
      "                          'files with new eviction walks started': 0,\n",
      "                          'force re-tuning of eviction workers once in a while': 0,\n",
      "                          'forced eviction - pages evicted that were clean count': 0,\n",
      "                          'forced eviction - pages evicted that were clean time (usecs)': 0,\n",
      "                          'forced eviction - pages evicted that were dirty count': 0,\n",
      "                          'forced eviction - pages evicted that were dirty time (usecs)': 0,\n",
      "                          'forced eviction - pages selected because of too many deleted items count': 0,\n",
      "                          'forced eviction - pages selected count': 0,\n",
      "                          'forced eviction - pages selected unable to be evicted count': 0,\n",
      "                          'forced eviction - pages selected unable to be evicted time': 0,\n",
      "                          'hazard pointer blocked page eviction': 0,\n",
      "                          'hazard pointer check calls': 0,\n",
      "                          'hazard pointer check entries walked': 0,\n",
      "                          'hazard pointer maximum array length': 0,\n",
      "                          'in-memory page passed criteria to be split': 0,\n",
      "                          'in-memory page splits': 0,\n",
      "                          'internal pages evicted': 0,\n",
      "                          'internal pages queued for eviction': 0,\n",
      "                          'internal pages seen by eviction walk': 0,\n",
      "                          'internal pages seen by eviction walk that are already queued': 0,\n",
      "                          'internal pages split during eviction': 0,\n",
      "                          'leaf pages split during eviction': 0,\n",
      "                          'maximum bytes configured': 8053063680.0,\n",
      "                          'maximum page size at eviction': 0,\n",
      "                          'modified pages evicted': 2,\n",
      "                          'modified pages evicted by application threads': 0,\n",
      "                          'operations timed out waiting for space in cache': 0,\n",
      "                          'overflow pages read into cache': 0,\n",
      "                          'page split during eviction deepened the tree': 0,\n",
      "                          'page written requiring cache overflow records': 0,\n",
      "                          'pages currently held in the cache': 19,\n",
      "                          'pages evicted by application threads': 0,\n",
      "                          'pages queued for eviction': 0,\n",
      "                          'pages queued for eviction post lru sorting': 0,\n",
      "                          'pages queued for urgent eviction': 0,\n",
      "                          'pages queued for urgent eviction during walk': 0,\n",
      "                          'pages read into cache': 0,\n",
      "                          'pages read into cache after truncate': 8,\n",
      "                          'pages read into cache after truncate in prepare state': 0,\n",
      "                          'pages read into cache requiring cache overflow entries': 0,\n",
      "                          'pages read into cache requiring cache overflow for checkpoint': 0,\n",
      "                          'pages read into cache skipping older cache overflow entries': 0,\n",
      "                          'pages read into cache with skipped cache overflow entries needed later': 0,\n",
      "                          'pages read into cache with skipped cache overflow entries needed later by checkpoint': 0,\n",
      "                          'pages requested from the cache': 349,\n",
      "                          'pages seen by eviction walk': 0,\n",
      "                          'pages seen by eviction walk that are already queued': 0,\n",
      "                          'pages selected for eviction unable to be evicted': 0,\n",
      "                          'pages selected for eviction unable to be evicted as the parent page has overflow items': 0,\n",
      "                          'pages selected for eviction unable to be evicted because of active children on an internal page': 0,\n",
      "                          'pages selected for eviction unable to be evicted because of failure in reconciliation': 0,\n",
      "                          'pages selected for eviction unable to be evicted due to newer modifications on a clean page': 0,\n",
      "                          'pages walked for eviction': 0,\n",
      "                          'pages written from cache': 18,\n",
      "                          'pages written requiring in-memory restoration': 0,\n",
      "                          'percentage overhead': 8,\n",
      "                          'tracked bytes belonging to internal pages in the cache': 4419,\n",
      "                          'tracked bytes belonging to leaf pages in the cache': 42821,\n",
      "                          'tracked dirty bytes in the cache': 28782,\n",
      "                          'tracked dirty pages in the cache': 2,\n",
      "                          'unmodified pages evicted': 0},\n",
      "                'capacity': {'background fsync file handles considered': 0,\n",
      "                             'background fsync file handles synced': 0,\n",
      "                             'background fsync time (msecs)': 0,\n",
      "                             'bytes read': 0,\n",
      "                             'bytes written for checkpoint': 32125,\n",
      "                             'bytes written for eviction': 0,\n",
      "                             'bytes written for log': 26496,\n",
      "                             'bytes written total': 58621,\n",
      "                             'threshold to call fsync': 0,\n",
      "                             'time waiting due to total capacity (usecs)': 0,\n",
      "                             'time waiting during checkpoint (usecs)': 0,\n",
      "                             'time waiting during eviction (usecs)': 0,\n",
      "                             'time waiting during logging (usecs)': 0,\n",
      "                             'time waiting during read (usecs)': 0},\n",
      "                'concurrentTransactions': {'read': {'available': 127,\n",
      "                                                    'out': 1,\n",
      "                                                    'totalTickets': 128},\n",
      "                                           'write': {'available': 128,\n",
      "                                                     'out': 0,\n",
      "                                                     'totalTickets': 128}},\n",
      "                'connection': {'auto adjusting condition resets': 20,\n",
      "                               'auto adjusting condition wait calls': 782,\n",
      "                               'detected system time went backwards': 0,\n",
      "                               'files currently open': 14,\n",
      "                               'memory allocations': 8998,\n",
      "                               'memory frees': 7994,\n",
      "                               'memory re-allocations': 779,\n",
      "                               'pthread mutex condition wait calls': 1741,\n",
      "                               'pthread mutex shared lock read-lock calls': 1803,\n",
      "                               'pthread mutex shared lock write-lock calls': 212,\n",
      "                               'total fsync I/Os': 55,\n",
      "                               'total read I/Os': 23,\n",
      "                               'total write I/Os': 73},\n",
      "                'cursor': {'cached cursor count': 13,\n",
      "                           'cursor bulk loaded cursor insert calls': 0,\n",
      "                           'cursor close calls that result in cache': 46,\n",
      "                           'cursor create calls': 81,\n",
      "                           'cursor insert calls': 66,\n",
      "                           'cursor insert key and value bytes': 33611,\n",
      "                           'cursor modify calls': 0,\n",
      "                           'cursor modify key and value bytes affected': 0,\n",
      "                           'cursor modify value bytes modified': 0,\n",
      "                           'cursor next calls': 33,\n",
      "                           'cursor operation restarted': 0,\n",
      "                           'cursor prev calls': 6,\n",
      "                           'cursor remove calls': 3,\n",
      "                           'cursor remove key bytes removed': 119,\n",
      "                           'cursor reserve calls': 0,\n",
      "                           'cursor reset calls': 386,\n",
      "                           'cursor search calls': 254,\n",
      "                           'cursor search near calls': 23,\n",
      "                           'cursor sweep buckets': 31,\n",
      "                           'cursor sweep cursors closed': 1,\n",
      "                           'cursor sweep cursors examined': 1,\n",
      "                           'cursor sweeps': 5,\n",
      "                           'cursor truncate calls': 0,\n",
      "                           'cursor update calls': 0,\n",
      "                           'cursor update key and value bytes': 0,\n",
      "                           'cursor update value size change': 0,\n",
      "                           'cursors reused from cache': 32,\n",
      "                           'open cursor count': 22},\n",
      "                'data-handle': {'connection data handle size': 456,\n",
      "                                'connection data handles currently active': 20,\n",
      "                                'connection sweep candidate became referenced': 0,\n",
      "                                'connection sweep dhandles closed': 1,\n",
      "                                'connection sweep dhandles removed from hash list': 4,\n",
      "                                'connection sweep time-of-death sets': 40,\n",
      "                                'connection sweeps': 13,\n",
      "                                'session dhandles swept': 2,\n",
      "                                'session sweep attempts': 39},\n",
      "                'lock': {'checkpoint lock acquisitions': 2,\n",
      "                         'checkpoint lock application thread wait time (usecs)': 2,\n",
      "                         'checkpoint lock internal thread wait time (usecs)': 0,\n",
      "                         'dhandle lock application thread time waiting (usecs)': 0,\n",
      "                         'dhandle lock internal thread time waiting (usecs)': 1,\n",
      "                         'dhandle read lock acquisitions': 519,\n",
      "                         'dhandle write lock acquisitions': 29,\n",
      "                         'durable timestamp queue lock application thread time waiting (usecs)': 0,\n",
      "                         'durable timestamp queue lock internal thread time waiting (usecs)': 0,\n",
      "                         'durable timestamp queue read lock acquisitions': 0,\n",
      "                         'durable timestamp queue write lock acquisitions': 0,\n",
      "                         'metadata lock acquisitions': 2,\n",
      "                         'metadata lock application thread wait time (usecs)': 0,\n",
      "                         'metadata lock internal thread wait time (usecs)': 0,\n",
      "                         'read timestamp queue lock application thread time waiting (usecs)': 0,\n",
      "                         'read timestamp queue lock internal thread time waiting (usecs)': 0,\n",
      "                         'read timestamp queue read lock acquisitions': 0,\n",
      "                         'read timestamp queue write lock acquisitions': 0,\n",
      "                         'schema lock acquisitions': 19,\n",
      "                         'schema lock application thread wait time (usecs)': 3,\n",
      "                         'schema lock internal thread wait time (usecs)': 5,\n",
      "                         'table lock application thread time waiting for the table lock (usecs)': 0,\n",
      "                         'table lock internal thread time waiting for the table lock (usecs)': 0,\n",
      "                         'table read lock acquisitions': 0,\n",
      "                         'table write lock acquisitions': 13,\n",
      "                         'txn global lock application thread time waiting (usecs)': 0,\n",
      "                         'txn global lock internal thread time waiting (usecs)': 0,\n",
      "                         'txn global read lock acquisitions': 22,\n",
      "                         'txn global write lock acquisitions': 11},\n",
      "                'log': {'busy returns attempting to switch slots': 0,\n",
      "                        'force archive time sleeping (usecs)': 0,\n",
      "                        'log bytes of payload data': 20241,\n",
      "                        'log bytes written': 26368,\n",
      "                        'log files manually zero-filled': 0,\n",
      "                        'log flush operations': 882,\n",
      "                        'log force write operations': 1018,\n",
      "                        'log force write operations skipped': 1017,\n",
      "                        'log records compressed': 20,\n",
      "                        'log records not compressed': 21,\n",
      "                        'log records too small to compress': 26,\n",
      "                        'log release advances write LSN': 15,\n",
      "                        'log scan operations': 0,\n",
      "                        'log scan records requiring two reads': 0,\n",
      "                        'log server thread advances write LSN': 1,\n",
      "                        'log server thread write LSN walk skipped': 1121,\n",
      "                        'log sync operations': 17,\n",
      "                        'log sync time duration (usecs)': 85374,\n",
      "                        'log sync_dir operations': 1,\n",
      "                        'log sync_dir time duration (usecs)': 6987,\n",
      "                        'log write operations': 67,\n",
      "                        'logging bytes consolidated': 25856,\n",
      "                        'maximum log file size': 104857600,\n",
      "                        'number of pre-allocated log files to create': 2,\n",
      "                        'pre-allocated log files not ready and missed': 1,\n",
      "                        'pre-allocated log files prepared': 2,\n",
      "                        'pre-allocated log files used': 0,\n",
      "                        'records processed by log scan': 0,\n",
      "                        'slot close lost race': 0,\n",
      "                        'slot close unbuffered waits': 0,\n",
      "                        'slot closures': 16,\n",
      "                        'slot join atomic update races': 0,\n",
      "                        'slot join calls atomic updates raced': 0,\n",
      "                        'slot join calls did not yield': 67,\n",
      "                        'slot join calls found active slot closed': 0,\n",
      "                        'slot join calls slept': 0,\n",
      "                        'slot join calls yielded': 0,\n",
      "                        'slot join found active slot closed': 0,\n",
      "                        'slot joins yield time (usecs)': 0,\n",
      "                        'slot transitions unable to find free slot': 0,\n",
      "                        'slot unbuffered writes': 0,\n",
      "                        'total in-memory size of compressed records': 29919,\n",
      "                        'total log buffer size': 33554432,\n",
      "                        'total size of compressed records': 14863,\n",
      "                        'written slots coalesced': 0,\n",
      "                        'yields waiting for previous log file close': 0},\n",
      "                'perf': {'file system read latency histogram (bucket 1) - 10-49ms': 0,\n",
      "                         'file system read latency histogram (bucket 2) - 50-99ms': 0,\n",
      "                         'file system read latency histogram (bucket 3) - 100-249ms': 0,\n",
      "                         'file system read latency histogram (bucket 4) - 250-499ms': 0,\n",
      "                         'file system read latency histogram (bucket 5) - 500-999ms': 0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         'file system read latency histogram (bucket 6) - 1000ms+': 0,\n",
      "                         'file system write latency histogram (bucket 1) - 10-49ms': 0,\n",
      "                         'file system write latency histogram (bucket 2) - 50-99ms': 0,\n",
      "                         'file system write latency histogram (bucket 3) - 100-249ms': 0,\n",
      "                         'file system write latency histogram (bucket 4) - 250-499ms': 0,\n",
      "                         'file system write latency histogram (bucket 5) - 500-999ms': 0,\n",
      "                         'file system write latency histogram (bucket 6) - 1000ms+': 0,\n",
      "                         'operation read latency histogram (bucket 1) - 100-249us': 0,\n",
      "                         'operation read latency histogram (bucket 2) - 250-499us': 0,\n",
      "                         'operation read latency histogram (bucket 3) - 500-999us': 0,\n",
      "                         'operation read latency histogram (bucket 4) - 1000-9999us': 0,\n",
      "                         'operation read latency histogram (bucket 5) - 10000us+': 0,\n",
      "                         'operation write latency histogram (bucket 1) - 100-249us': 0,\n",
      "                         'operation write latency histogram (bucket 2) - 250-499us': 0,\n",
      "                         'operation write latency histogram (bucket 3) - 500-999us': 0,\n",
      "                         'operation write latency histogram (bucket 4) - 1000-9999us': 0,\n",
      "                         'operation write latency histogram (bucket 5) - 10000us+': 0},\n",
      "                'reconciliation': {'fast-path pages deleted': 0,\n",
      "                                   'page reconciliation calls': 21,\n",
      "                                   'page reconciliation calls for eviction': 1,\n",
      "                                   'pages deleted': 4,\n",
      "                                   'split bytes currently awaiting free': 0,\n",
      "                                   'split objects currently awaiting free': 0},\n",
      "                'session': {'open session count': 19,\n",
      "                            'session query timestamp calls': 0,\n",
      "                            'table alter failed calls': 0,\n",
      "                            'table alter successful calls': 0,\n",
      "                            'table alter unchanged and skipped': 0,\n",
      "                            'table compact failed calls': 0,\n",
      "                            'table compact successful calls': 0,\n",
      "                            'table create failed calls': 0,\n",
      "                            'table create successful calls': 10,\n",
      "                            'table drop failed calls': 0,\n",
      "                            'table drop successful calls': 1,\n",
      "                            'table import failed calls': 0,\n",
      "                            'table import successful calls': 0,\n",
      "                            'table rebalance failed calls': 0,\n",
      "                            'table rebalance successful calls': 0,\n",
      "                            'table rename failed calls': 0,\n",
      "                            'table rename successful calls': 0,\n",
      "                            'table salvage failed calls': 0,\n",
      "                            'table salvage successful calls': 0,\n",
      "                            'table truncate failed calls': 0,\n",
      "                            'table truncate successful calls': 0,\n",
      "                            'table verify failed calls': 0,\n",
      "                            'table verify successful calls': 0},\n",
      "                'snapshot-window-settings': {'cache pressure percentage threshold': 95,\n",
      "                                             'current available snapshots window size in seconds': 0,\n",
      "                                             'current cache pressure percentage': 0,\n",
      "                                             'latest majority snapshot timestamp available': 'Dec '\n",
      "                                                                                             '31 '\n",
      "                                                                                             '19:00:00:0',\n",
      "                                             'max target available snapshots window size in seconds': 5,\n",
      "                                             'oldest majority snapshot timestamp available': 'Dec '\n",
      "                                                                                             '31 '\n",
      "                                                                                             '19:00:00:0',\n",
      "                                             'target available snapshots window size in seconds': 5,\n",
      "                                             'total number of SnapshotTooOld errors': 0},\n",
      "                'thread-state': {'active filesystem fsync calls': 0,\n",
      "                                 'active filesystem read calls': 0,\n",
      "                                 'active filesystem write calls': 0},\n",
      "                'thread-yield': {'application thread time evicting (usecs)': 0,\n",
      "                                 'application thread time waiting for cache (usecs)': 0,\n",
      "                                 'connection close blocked waiting for transaction state stabilization': 0,\n",
      "                                 'connection close yielded for lsm manager shutdown': 0,\n",
      "                                 'data handle lock yielded': 0,\n",
      "                                 'get reference for page index and slot time sleeping (usecs)': 0,\n",
      "                                 'log server sync yielded for log write': 0,\n",
      "                                 'page access yielded due to prepare state change': 0,\n",
      "                                 'page acquire busy blocked': 0,\n",
      "                                 'page acquire eviction blocked': 0,\n",
      "                                 'page acquire locked blocked': 0,\n",
      "                                 'page acquire read blocked': 0,\n",
      "                                 'page acquire time sleeping (usecs)': 0,\n",
      "                                 'page delete rollback time sleeping for state change (usecs)': 0,\n",
      "                                 'page reconciliation yielded due to child modification': 0},\n",
      "                'transaction': {'Number of prepared updates': 0,\n",
      "                                'Number of prepared updates added to cache overflow': 0,\n",
      "                                'durable timestamp queue entries walked': 0,\n",
      "                                'durable timestamp queue insert to empty': 0,\n",
      "                                'durable timestamp queue inserts to head': 0,\n",
      "                                'durable timestamp queue inserts total': 0,\n",
      "                                'durable timestamp queue length': 0,\n",
      "                                'number of named snapshots created': 0,\n",
      "                                'number of named snapshots dropped': 0,\n",
      "                                'prepared transactions': 0,\n",
      "                                'prepared transactions committed': 0,\n",
      "                                'prepared transactions currently active': 0,\n",
      "                                'prepared transactions rolled back': 0,\n",
      "                                'query timestamp calls': 124,\n",
      "                                'read timestamp queue entries walked': 0,\n",
      "                                'read timestamp queue insert to empty': 0,\n",
      "                                'read timestamp queue inserts to head': 0,\n",
      "                                'read timestamp queue inserts total': 0,\n",
      "                                'read timestamp queue length': 0,\n",
      "                                'rollback to stable calls': 0,\n",
      "                                'rollback to stable updates aborted': 0,\n",
      "                                'rollback to stable updates removed from cache overflow': 0,\n",
      "                                'set timestamp calls': 0,\n",
      "                                'set timestamp durable calls': 0,\n",
      "                                'set timestamp durable updates': 0,\n",
      "                                'set timestamp oldest calls': 0,\n",
      "                                'set timestamp oldest updates': 0,\n",
      "                                'set timestamp stable calls': 0,\n",
      "                                'set timestamp stable updates': 0,\n",
      "                                'transaction begins': 39,\n",
      "                                'transaction checkpoint currently running': 0,\n",
      "                                'transaction checkpoint generation': 3,\n",
      "                                'transaction checkpoint max time (msecs)': 56,\n",
      "                                'transaction checkpoint min time (msecs)': 24,\n",
      "                                'transaction checkpoint most recent time (msecs)': 24,\n",
      "                                'transaction checkpoint scrub dirty target': 0,\n",
      "                                'transaction checkpoint scrub time (msecs)': 0,\n",
      "                                'transaction checkpoint total time (msecs)': 80,\n",
      "                                'transaction checkpoints': 2,\n",
      "                                'transaction checkpoints skipped because database was clean': 0,\n",
      "                                'transaction failures due to cache overflow': 0,\n",
      "                                'transaction fsync calls for checkpoint after allocating the transaction ID': 2,\n",
      "                                'transaction fsync duration for checkpoint after allocating the transaction ID (usecs)': 9567,\n",
      "                                'transaction range of IDs currently pinned': 0,\n",
      "                                'transaction range of IDs currently pinned by a checkpoint': 0,\n",
      "                                'transaction range of IDs currently pinned by named snapshots': 0,\n",
      "                                'transaction range of timestamps currently pinned': 0,\n",
      "                                'transaction range of timestamps pinned by a checkpoint': 0,\n",
      "                                'transaction range of timestamps pinned by the oldest active read timestamp': 0,\n",
      "                                'transaction range of timestamps pinned by the oldest timestamp': 0,\n",
      "                                'transaction read timestamp of the oldest active reader': 0,\n",
      "                                'transaction sync calls': 0,\n",
      "                                'transactions committed': 13,\n",
      "                                'transactions rolled back': 26,\n",
      "                                'update conflicts': 0},\n",
      "                'uri': 'statistics:'}}\n"
     ]
    }
   ],
   "source": [
    "# Issue the serverStatus command and print the results\n",
    "serverStatusResult=db.command(\"serverStatus\")\n",
    "pprint(serverStatusResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = client['energy_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'local']\n"
     ]
    }
   ],
   "source": [
    "print(client.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_collection = mydb['energy_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_results = energy_collection.insert_many(environmental_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_gdp_results = energy_collection.insert_many(pop_gdp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = energy_collection.find({'state':'Oregon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "batch_size() missing 1 required positional argument: 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-414-417979349728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: batch_size() missing 1 required positional argument: 'batch_size'"
     ]
    }
   ],
   "source": [
    "query_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "316px",
    "left": "916px",
    "right": "20px",
    "top": "120px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
